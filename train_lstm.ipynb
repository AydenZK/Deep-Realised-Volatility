{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.003461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.003113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.004070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.003357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.002090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  time_id    target\n",
       "0              0        5  0.004136\n",
       "1              0       11  0.001445\n",
       "2              0       16  0.002168\n",
       "3              0       31  0.002195\n",
       "4              0       62  0.001747\n",
       "...          ...      ...       ...\n",
       "428927       126    32751  0.003461\n",
       "428928       126    32753  0.003113\n",
       "428929       126    32758  0.004070\n",
       "428930       126    32763  0.003357\n",
       "428931       126    32767  0.002090\n",
       "\n",
       "[428932 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = Path(os.getcwd()).joinpath('data')\n",
    "train_targets = pd.read_csv(DATA_DIR.joinpath('train.csv'))\n",
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_ids = train_targets.stock_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.99500000e+02, 1.00641095e+04, 1.90405617e+02, 6.63335529e+00,\n",
       "        8.36687157e+02, 1.00000680e+00, 1.00000553e+00, 2.72614582e-03,\n",
       "        2.17380546e-03, 2.88276171e-03, 2.29133757e-03, 2.79193802e-03,\n",
       "        2.22625789e-03, 2.95122026e-03, 2.34570845e-03, 2.35567682e-03]),\n",
       " array([1.73204878e+02, 1.31414606e+04, 3.79309559e+02, 7.66123567e+00,\n",
       "        6.11827585e+03, 3.68989322e-03, 3.70745216e-03, 2.67012408e-03,\n",
       "        2.11603016e-03, 2.87719295e-03, 2.27091025e-03, 2.34281279e-03,\n",
       "        1.85399888e-03, 2.53002282e-03, 1.99385344e-03, 2.26015967e-03]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_means = np.load(DATA_DIR.joinpath('seq_features').joinpath('feature_means.npy'))\n",
    "feature_stds = np.load(DATA_DIR.joinpath('seq_features').joinpath('feature_stds.npy'))\n",
    "\n",
    "feature_means, feature_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3787f159b1154bfa9197a098fe1d99d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = None\n",
    "device = torch.device('cpu')\n",
    "for stock_id in tqdm(stock_ids):\n",
    "    stock_df = pd.read_parquet(DATA_DIR.joinpath('seq_features').joinpath(f'stock_{stock_id}_seq.parquet'))\n",
    "\n",
    "    stock_array = (\n",
    "        stock_df\n",
    "        .sort_values(['time_id', 'seconds_in_bucket'])\n",
    "        .drop(columns=['time_id', 'stock_id'])\n",
    "        .to_numpy()\n",
    "    )\n",
    "    stock_array_scaled = ((stock_array - feature_means) / feature_stds).astype(np.float32)\n",
    "\n",
    "    stock_tensor = torch.tensor(stock_array_scaled.reshape((-1, 600, 16))).to(device)\n",
    "    if data is None:\n",
    "        data = stock_tensor\n",
    "    else:\n",
    "        data = torch.cat([data, stock_tensor], dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of tensor: 16470988800 bytes\n",
      "Memory usage of tensor: 15707.96 MB\n",
      "Memory usage of tensor: 15.34 GB\n"
     ]
    }
   ],
   "source": [
    "# Calculate memory usage in bytes\n",
    "memory_bytes = data.element_size() * data.nelement()\n",
    "\n",
    "# Convert to megabytes (MB) and gigabytes (GB)\n",
    "memory_mb = memory_bytes / (1024 ** 2)\n",
    "memory_gb = memory_bytes / (1024 ** 3)\n",
    "\n",
    "print(f\"Memory usage of tensor: {memory_bytes} bytes\")\n",
    "print(f\"Memory usage of tensor: {memory_mb:.2f} MB\")\n",
    "print(f\"Memory usage of tensor: {memory_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Dataset\n",
    "import numpy as np\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data  # Features tensor\n",
    "        self.targets = targets  # Targets tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]  # Return a tuple (features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StockDataset(data, torch.tensor(train_targets['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "num_samples = data.shape[0]\n",
    "indices = np.random.permutation(num_samples)\n",
    "split_idx = int(num_samples * 0.8)\n",
    "train_indices, val_indices = indices[:split_idx], indices[split_idx:]\n",
    "\n",
    "# Create DataLoaders using SubsetRandomSampler\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, num_features=16, hidden_size=64, num_layers=2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_features,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, num_features)\n",
    "        out, _ = self.lstm(x)\n",
    "        # Use the last hidden state\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    # Adding a small epsilon to y_true to prevent division by zero\n",
    "    epsilon = 1e-8\n",
    "    return torch.sqrt(torch.mean(((y_true - y_pred) / (y_true + epsilon)) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Training Loss: 0.8024, Validation Loss: 0.1979\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "num_epochs = 4\n",
    "\n",
    "model = LSTMModel(num_features=16).to(device)\n",
    "criterion = rmspe\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs = torch.nan_to_num(inputs, nan=0.0).to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = torch.nan_to_num(inputs, nan=0.0).to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    # Compute average losses\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
