{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(os.getcwd()).parent.joinpath(\"data\")\n",
    "\n",
    "RVOL_GRID = {\n",
    "    \"wap2_wt\": [0, 0.15],\n",
    "    \"ewa_alpha\": [0.2, 0.6, 1],\n",
    "    \"shift_size\": [1, 3, 5] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wap_ewa(df, wap2_wt, ewa_alpha):\n",
    "    df['wap1'] = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    df['wap2'] = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    df[f'wap_{wap2_wt}_{ewa_alpha}'] = (df['wap1'] * (1 - wap2_wt) + df['wap2'] * wap2_wt).ewm(alpha=ewa_alpha).mean()\n",
    "    return df\n",
    "\n",
    "def spread_ratio(df):\n",
    "    df['spread_ratio'] = ((df['ask_price1'] / df['bid_price1'] - 1) * 10000)\n",
    "    return df\n",
    "\n",
    "def volume_imbalance(df):\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    return df\n",
    "\n",
    "def calc_rvol(x: pd.Series, shift_size: int):\n",
    "    x = np.log(x).diff(shift_size)\n",
    "    return np.sqrt(np.sum(x**2))\n",
    "\n",
    "def create_rvol_calc(shift_size):\n",
    "    return lambda x: calc_rvol(x, shift_size)\n",
    "\n",
    "def engineer_book_features(stock_id, train_test):\n",
    "    file_path = load_data(stock_id, \"book\", train_test)\n",
    "    df_book = pd.read_parquet(file_path)\n",
    "\n",
    "    for wap2_wt, ewa_alpha in itertools.product(*list(RVOL_GRID.values())[:2]):\n",
    "        df_book = wap_ewa(df_book, wap2_wt, ewa_alpha)\n",
    "\n",
    "    df_book = spread_ratio(df_book)\n",
    "    df_book = volume_imbalance(df_book)\n",
    "    \n",
    "    agg_dict = {\n",
    "        'spread_ratio_mean': ('spread_ratio', 'mean'),\n",
    "        'spread_ratio_std': ('spread_ratio', 'std'),\n",
    "        'volume_imbalance': ('volume_imbalance', 'mean')\n",
    "    }\n",
    "\n",
    "    for wap2_wt, ewa_alpha, shift_size in itertools.product(*RVOL_GRID.values()):\n",
    "        agg_dict[f'rvol_{wap2_wt}_{ewa_alpha}_{shift_size}'] = (f\"wap_{wap2_wt}_{ewa_alpha}\", create_rvol_calc(shift_size))\n",
    "\n",
    "    df_book_features = df_book.groupby('time_id').agg(**agg_dict).reset_index()\n",
    "    df_book_features['stock_id'] = stock_id\n",
    "    \n",
    "    return df_book_features\n",
    "\n",
    "def engineer_trade_features(stock_id, train_test):\n",
    "    file_path = load_data(stock_id, \"trade\", train_test)\n",
    "    df_trade = pd.read_parquet(file_path)\n",
    "\n",
    "    df_trade_features = df_trade.groupby('time_id').agg(\n",
    "        trade_volume = ('size', 'sum'),\n",
    "        trade_count = ('order_count', 'sum'),\n",
    "    ).reset_index()\n",
    "    df_trade_features['stock_id'] = stock_id\n",
    "\n",
    "    return df_trade_features\n",
    "\n",
    "def load_data(stock_id: int, data_type: str, train_test: str):\n",
    "    file_dir = DATA_DIR.joinpath(f\"{data_type}_{train_test}.parquet\").joinpath(f\"stock_id={stock_id}\")\n",
    "    file_name = os.listdir(file_dir)[0]\n",
    "    full_path = file_dir.joinpath(file_name)\n",
    "    return full_path\n",
    "\n",
    "\n",
    "def for_joblib(stock_id, train_test):\n",
    "    df_bk = engineer_book_features(stock_id, train_test)\n",
    "    df_tr = engineer_trade_features(stock_id, train_test)\n",
    "    \n",
    "    df_tmp = pd.merge(df_bk, df_tr, on=['stock_id', 'time_id'], how='left')\n",
    "\n",
    "    return df_tmp\n",
    "\n",
    "def engineer_features(stock_ids: List[int], train_test: str):\n",
    "    dfs = Parallel(n_jobs=-1, verbose=1)(delayed(for_joblib)(stock_id, train_test) for stock_id in stock_ids)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df[\"row_id\"] = df[\"stock_id\"].astype(str) + \"-\" + df[\"time_id\"].astype(str)\n",
    "    return df\n",
    "\n",
    "def engineer_data(load_local: bool = False, save: bool = False) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    if load_local:\n",
    "        df_train = pd.read_parquet(DATA_DIR.joinpath(\"train_features.parquet\"))\n",
    "        df_test = pd.read_parquet(DATA_DIR.joinpath(\"test_features.parquet\"))\n",
    "        return df_train, df_test\n",
    "    \n",
    "    df_train_targets = pd.read_csv(DATA_DIR.joinpath(\"train.csv\"))\n",
    "    train_ids = df_train_targets[\"stock_id\"].unique()\n",
    "    df_train = engineer_features(train_ids, \"train\")\n",
    "    df_train = pd.merge(df_train, df_train_targets, on=['stock_id', 'time_id'], how='inner')\n",
    "\n",
    "    test_df = pd.read_csv(DATA_DIR.joinpath(\"test.csv\"))\n",
    "    test_ids = test_df[\"stock_id\"].unique()\n",
    "    df_test = engineer_features(test_ids, \"test\")\n",
    "\n",
    "    if save:\n",
    "        df_train.to_parquet(DATA_DIR.joinpath(\"train_features.parquet\"))\n",
    "        df_test.to_parquet(DATA_DIR.joinpath(\"test_features.parquet\"))\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = engineer_data(load_local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "def feval_rmspe(y_pred, lgb_train: lgb.Dataset):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', round(rmspe(y_true, y_pred),8), False\n",
    "\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "def calc_model_importance(model, feature_names=None, importance_type='gain'):\n",
    "    importance_df = pd.DataFrame(model.feature_importance(importance_type=importance_type),\n",
    "                                 index=feature_names,\n",
    "                                 columns=['importance']).sort_values('importance')\n",
    "    return importance_df\n",
    "\n",
    "def plot_importance(importance_df, title='',\n",
    "                    save_filepath=None, figsize=(8, 12)):\n",
    "    _, ax = plt.subplots(figsize=figsize)\n",
    "    importance_df.plot.barh(ax=ax)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    if save_filepath is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_filepath)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = train.drop(columns=['row_id', 'target', 'time_id']).values\n",
    "y_train = train['target'].values\n",
    "\n",
    "X_valid = valid.drop(columns=['row_id', 'target', 'time_id']).values\n",
    "y_valid = valid['target'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Tuple\n",
    "from dataclasses import dataclass\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelResult:\n",
    "    model: lgb.Booster\n",
    "    params: Dict[str, Any]\n",
    "    train_rmspe: float\n",
    "    valid_rmspe: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GridSearchResult:\n",
    "    search_results: pd.DataFrame\n",
    "    best_model: ModelResult\n",
    "\n",
    "\n",
    "def mlp_trainer(X_train, y_train, X_valid, y_valid, params) -> ModelResult:\n",
    "    model = MLPRegressor(random_state=42, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    train_rmspe = rmspe(y_train, y_train_pred)\n",
    "    valid_rmspe = rmspe(y_valid, y_valid_pred)\n",
    "    \n",
    "    return ModelResult(model, params, train_rmspe, valid_rmspe)\n",
    "\n",
    "def lr_trainer(X_train, y_train, X_valid, y_valid, params) -> ModelResult:\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    train_rmspe = rmspe(y_train, y_train_pred)\n",
    "    valid_rmspe = rmspe(y_valid, y_valid_pred)\n",
    "\n",
    "    return ModelResult(model, params, train_rmspe, valid_rmspe)\n",
    "\n",
    "def lgbm_trainer(X_train, y_train, X_valid, y_valid, params) -> ModelResult:\n",
    "    X_train_lgb = lgb.Dataset(X_train, y_train, categorical_feature=[\"stock_id\"], weight=1/np.square(y_train))\n",
    "    X_valid_lgb = lgb.Dataset(X_valid, y_valid, categorical_feature=[\"stock_id\"], weight=1/np.square(y_valid))\n",
    "\n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        X_train_lgb, \n",
    "        valid_sets=[X_train_lgb, X_valid_lgb], \n",
    "        num_boost_round=1000, \n",
    "        feval=feval_rmspe\n",
    "    )\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    train_rmspe = rmspe(y_train, y_train_pred)\n",
    "    valid_rmspe = rmspe(y_valid, y_valid_pred)\n",
    "\n",
    "    return ModelResult(model, params, train_rmspe, valid_rmspe)\n",
    "\n",
    "\n",
    "def cv_train(\n",
    "    _model_trainer: callable,\n",
    "    kf: KFold, \n",
    "    X: pd.DataFrame, \n",
    "    y: pd.DataFrame,\n",
    "    params: Dict[str, Any]\n",
    ") -> Tuple[Dict[str, Any], ModelResult]:\n",
    "    \"\"\"Cross Validation Run\"\"\"\n",
    "    cv_models: List[ModelResult] = []\n",
    "\n",
    "    for train_idx, valid_idx in tqdm(kf.split(X)):\n",
    "        X_train, y_train = X.loc[train_idx], y[train_idx]\n",
    "        X_valid, y_valid = X.loc[valid_idx], y[valid_idx]\n",
    "\n",
    "        model_res = _model_trainer(X_train, y_train, X_valid, y_valid, params)\n",
    "        cv_models.append(model_res)\n",
    "\n",
    "    cv_results = params.copy()\n",
    "    cv_results.update({\n",
    "        \"train_rmspe\": np.mean([m.train_rmspe for m in cv_models]),\n",
    "        \"valid_rmspe\": np.mean([m.valid_rmspe for m in cv_models]),\n",
    "    })\n",
    "    best_cv_model = cv_models[np.argmax([m.valid_rmspe for m in cv_models])]\n",
    "    \n",
    "    return GridSearchResult(pd.DataFrame([cv_results]), best_cv_model)\n",
    "\n",
    "\n",
    "def grid_search(\n",
    "    _model_trainer: callable,\n",
    "    X: pd.DataFrame, \n",
    "    y: pd.DataFrame,\n",
    "    search_grid: Dict[str, List[Any]],\n",
    "    n_iter: int, \n",
    "    cv: int = 1, \n",
    "    randomise: bool = True,\n",
    "    n_jobs: int = -1\n",
    ") -> GridSearchResult:\n",
    "    \"\"\" Generalized Grid Searcher\"\"\"\n",
    "    \n",
    "    # Construct the search grid\n",
    "    param_combinations = [\n",
    "        dict(zip(search_grid.keys(), p))\n",
    "        for p in itertools.product(*search_grid.values())\n",
    "    ]\n",
    "    if randomise:\n",
    "        param_combinations = np.random.choice(param_combinations, n_iter)\n",
    "\n",
    "    # Setup the cross validation\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # Run the grid search\n",
    "    results: List[GridSearchResult] = Parallel(n_jobs=-n_jobs)(delayed(cv_train)(_model_trainer, kf, X, y, params) for params in tqdm(param_combinations))\n",
    "\n",
    "    # Collect the results\n",
    "    search_results = pd.concat([r.search_results for r in results], ignore_index=True)\n",
    "    best_model = results[np.argmax([r.best_model.valid_rmspe for r in results])].best_model\n",
    "\n",
    "    return GridSearchResult(search_results, best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(DATA_DIR.joinpath(\"train_features.parquet\"))\n",
    "df_test = pd.read_parquet(DATA_DIR.joinpath(\"test_features.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>spread_ratio_mean</th>\n",
       "      <th>spread_ratio_std</th>\n",
       "      <th>volume_imbalance</th>\n",
       "      <th>rvol_0_0.2_1</th>\n",
       "      <th>rvol_0_0.2_3</th>\n",
       "      <th>rvol_0_0.2_5</th>\n",
       "      <th>rvol_0_0.6_1</th>\n",
       "      <th>rvol_0_0.6_3</th>\n",
       "      <th>rvol_0_0.6_5</th>\n",
       "      <th>...</th>\n",
       "      <th>rvol_0.15_0.6_3</th>\n",
       "      <th>rvol_0.15_0.6_5</th>\n",
       "      <th>rvol_0.15_1_1</th>\n",
       "      <th>rvol_0.15_1_3</th>\n",
       "      <th>rvol_0.15_1_5</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>trade_volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>8.522233</td>\n",
       "      <td>2.115166</td>\n",
       "      <td>134.894040</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.005089</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0</td>\n",
       "      <td>3179.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.004136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>3.942811</td>\n",
       "      <td>1.572313</td>\n",
       "      <td>142.050000</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0-11</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>7.254260</td>\n",
       "      <td>1.636399</td>\n",
       "      <td>141.414894</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0-16</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>8.608392</td>\n",
       "      <td>2.802506</td>\n",
       "      <td>146.216667</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0-31</td>\n",
       "      <td>0.002195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>3.972501</td>\n",
       "      <td>1.300607</td>\n",
       "      <td>123.846591</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0-62</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>32751</td>\n",
       "      <td>8.783802</td>\n",
       "      <td>2.352351</td>\n",
       "      <td>161.638710</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>0.005820</td>\n",
       "      <td>126</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>126-32751</td>\n",
       "      <td>0.003461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>32753</td>\n",
       "      <td>7.058147</td>\n",
       "      <td>2.279731</td>\n",
       "      <td>150.578475</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>126</td>\n",
       "      <td>2323.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>126-32753</td>\n",
       "      <td>0.003113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>32758</td>\n",
       "      <td>7.392257</td>\n",
       "      <td>2.399711</td>\n",
       "      <td>254.406250</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.003340</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.004424</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>126</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>126-32758</td>\n",
       "      <td>0.004070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>32763</td>\n",
       "      <td>5.301715</td>\n",
       "      <td>1.718243</td>\n",
       "      <td>145.654135</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.004994</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>126</td>\n",
       "      <td>9389.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>126-32763</td>\n",
       "      <td>0.003357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>32767</td>\n",
       "      <td>4.318035</td>\n",
       "      <td>1.253924</td>\n",
       "      <td>177.442396</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>126</td>\n",
       "      <td>5325.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>126-32767</td>\n",
       "      <td>0.002090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_id  spread_ratio_mean  spread_ratio_std  volume_imbalance  \\\n",
       "0             5           8.522233          2.115166        134.894040   \n",
       "1            11           3.942811          1.572313        142.050000   \n",
       "2            16           7.254260          1.636399        141.414894   \n",
       "3            31           8.608392          2.802506        146.216667   \n",
       "4            62           3.972501          1.300607        123.846591   \n",
       "...         ...                ...               ...               ...   \n",
       "428927    32751           8.783802          2.352351        161.638710   \n",
       "428928    32753           7.058147          2.279731        150.578475   \n",
       "428929    32758           7.392257          2.399711        254.406250   \n",
       "428930    32763           5.301715          1.718243        145.654135   \n",
       "428931    32767           4.318035          1.253924        177.442396   \n",
       "\n",
       "        rvol_0_0.2_1  rvol_0_0.2_3  rvol_0_0.2_5  rvol_0_0.6_1  rvol_0_0.6_3  \\\n",
       "0           0.001141      0.002906      0.004391      0.002651      0.005089   \n",
       "1           0.001013      0.002489      0.003464      0.001204      0.002011   \n",
       "2           0.000622      0.001629      0.002526      0.001356      0.002629   \n",
       "3           0.001037      0.002614      0.003759      0.001764      0.003556   \n",
       "4           0.000718      0.001767      0.002465      0.001238      0.002352   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "428927      0.000957      0.002344      0.003396      0.002232      0.004236   \n",
       "428928      0.000981      0.002330      0.003395      0.002312      0.004043   \n",
       "428929      0.001371      0.003340      0.004678      0.002179      0.003865   \n",
       "428930      0.000983      0.002440      0.003596      0.002229      0.004270   \n",
       "428931      0.000550      0.001358      0.002012      0.001227      0.002232   \n",
       "\n",
       "        rvol_0_0.6_5  ...  rvol_0.15_0.6_3  rvol_0.15_0.6_5  rvol_0.15_1_1  \\\n",
       "0           0.006629  ...         0.004688         0.006222       0.003942   \n",
       "1           0.002148  ...         0.001892         0.002001       0.001020   \n",
       "2           0.003570  ...         0.002450         0.003421       0.002165   \n",
       "3           0.004645  ...         0.003452         0.004520       0.002463   \n",
       "4           0.002963  ...         0.002140         0.002689       0.001692   \n",
       "...              ...  ...              ...              ...            ...   \n",
       "428927      0.005424  ...         0.003852         0.004991       0.003188   \n",
       "428928      0.005178  ...         0.003764         0.004859       0.003622   \n",
       "428929      0.004649  ...         0.003668         0.004424       0.002990   \n",
       "428930      0.005619  ...         0.004083         0.005462       0.003281   \n",
       "428931      0.002939  ...         0.002158         0.002810       0.001908   \n",
       "\n",
       "        rvol_0.15_1_3  rvol_0.15_1_5  stock_id  trade_volume  trade_count  \\\n",
       "0            0.005861       0.007139         0        3179.0        110.0   \n",
       "1            0.001454       0.001489         0        1289.0         57.0   \n",
       "2            0.003070       0.003893         0        2161.0         68.0   \n",
       "3            0.004044       0.004972         0        1962.0         59.0   \n",
       "4            0.002420       0.002888         0        1791.0         89.0   \n",
       "...               ...            ...       ...           ...          ...   \n",
       "428927       0.004795       0.005820       126        2570.0        103.0   \n",
       "428928       0.004824       0.005783       126        2323.0        147.0   \n",
       "428929       0.004149       0.004785       126        3740.0         98.0   \n",
       "428930       0.004994       0.006290       126        9389.0        234.0   \n",
       "428931       0.002701       0.003324       126        5325.0        108.0   \n",
       "\n",
       "           row_id    target  \n",
       "0             0-5  0.004136  \n",
       "1            0-11  0.001445  \n",
       "2            0-16  0.002168  \n",
       "3            0-31  0.002195  \n",
       "4            0-62  0.001747  \n",
       "...           ...       ...  \n",
       "428927  126-32751  0.003461  \n",
       "428928  126-32753  0.003113  \n",
       "428929  126-32758  0.004070  \n",
       "428930  126-32763  0.003357  \n",
       "428931  126-32767  0.002090  \n",
       "\n",
       "[428932 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c8fdb16dc74e9abb5ea192afc1ca70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3602f72d57914c1ebfc5800aa886f324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001796\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000645878\ttraining's RMSPE: 0.299269\tvalid_1's rmse: 0.000660417\tvalid_1's RMSPE: 0.304579\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001804\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000645166\ttraining's RMSPE: 0.298116\tvalid_1's rmse: 0.000666301\tvalid_1's RMSPE: 0.309839\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000644642\ttraining's RMSPE: 0.298278\tvalid_1's rmse: 0.000663286\tvalid_1's RMSPE: 0.307195\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.00064492\ttraining's RMSPE: 0.298674\tvalid_1's rmse: 0.000659594\tvalid_1's RMSPE: 0.304663\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b874686a55794eab8708c3d864e5055d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001796\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[453]\ttraining's rmse: 0.000441867\ttraining's RMSPE: 0.20474\tvalid_1's rmse: 0.000530482\tvalid_1's RMSPE: 0.244654\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001804\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's rmse: 0.000454973\ttraining's RMSPE: 0.210232\tvalid_1's rmse: 0.000543101\tvalid_1's RMSPE: 0.252549\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[441]\ttraining's rmse: 0.000442603\ttraining's RMSPE: 0.204794\tvalid_1's rmse: 0.000532582\tvalid_1's RMSPE: 0.246661\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[427]\ttraining's rmse: 0.00044502\ttraining's RMSPE: 0.206097\tvalid_1's rmse: 0.000527699\tvalid_1's RMSPE: 0.243741\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2cf4ed1f6244a6a6fda20feb255904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001796\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's rmse: 0.000387375\ttraining's RMSPE: 0.179491\tvalid_1's rmse: 0.000537508\tvalid_1's RMSPE: 0.247894\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001804\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's rmse: 0.000408252\ttraining's RMSPE: 0.188644\tvalid_1's rmse: 0.000556387\tvalid_1's RMSPE: 0.258727\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's rmse: 0.000396679\ttraining's RMSPE: 0.183544\tvalid_1's rmse: 0.000541969\tvalid_1's RMSPE: 0.251009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's rmse: 0.000396761\ttraining's RMSPE: 0.183747\tvalid_1's rmse: 0.000536547\tvalid_1's RMSPE: 0.247828\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9601e8e1f5649deb00142cefdf495a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001796\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[514]\ttraining's rmse: 0.000463402\ttraining's RMSPE: 0.214718\tvalid_1's rmse: 0.000528107\tvalid_1's RMSPE: 0.243558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001804\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[417]\ttraining's rmse: 0.000472\ttraining's RMSPE: 0.2181\tvalid_1's rmse: 0.000539314\tvalid_1's RMSPE: 0.250788\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[486]\ttraining's rmse: 0.000464779\ttraining's RMSPE: 0.215055\tvalid_1's rmse: 0.000530891\tvalid_1's RMSPE: 0.245878\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[537]\ttraining's rmse: 0.000461056\ttraining's RMSPE: 0.213524\tvalid_1's rmse: 0.000525453\tvalid_1's RMSPE: 0.242704\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46abb0a8bd084ea2b27d489908e48018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001796\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[488]\ttraining's rmse: 0.000465528\ttraining's RMSPE: 0.215703\tvalid_1's rmse: 0.000528392\tvalid_1's RMSPE: 0.24369\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001804\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's rmse: 0.000472506\ttraining's RMSPE: 0.218334\tvalid_1's rmse: 0.000539468\tvalid_1's RMSPE: 0.25086\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[490]\ttraining's rmse: 0.000464421\ttraining's RMSPE: 0.214889\tvalid_1's rmse: 0.000530789\tvalid_1's RMSPE: 0.245831\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[551]\ttraining's rmse: 0.000459905\ttraining's RMSPE: 0.212991\tvalid_1's rmse: 0.000525424\tvalid_1's RMSPE: 0.24269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6c6771ba6045ab87a6fb1aa952cdd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001796\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[275]\ttraining's rmse: 0.000385475\ttraining's RMSPE: 0.178611\tvalid_1's rmse: 0.000534703\tvalid_1's RMSPE: 0.246601\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001804\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's rmse: 0.000395077\ttraining's RMSPE: 0.182556\tvalid_1's rmse: 0.000550729\tvalid_1's RMSPE: 0.256097\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[284]\ttraining's rmse: 0.000381144\ttraining's RMSPE: 0.176357\tvalid_1's rmse: 0.000539727\tvalid_1's RMSPE: 0.24997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[275]\ttraining's rmse: 0.000385184\ttraining's RMSPE: 0.178386\tvalid_1's rmse: 0.000533936\tvalid_1's RMSPE: 0.246622\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b340591a604d33a76167c5ea5d624e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001796\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[514]\ttraining's rmse: 0.000463402\ttraining's RMSPE: 0.214718\tvalid_1's rmse: 0.000528107\tvalid_1's RMSPE: 0.243558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001804\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[417]\ttraining's rmse: 0.000472\ttraining's RMSPE: 0.2181\tvalid_1's rmse: 0.000539314\tvalid_1's RMSPE: 0.250788\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[486]\ttraining's rmse: 0.000464779\ttraining's RMSPE: 0.215055\tvalid_1's rmse: 0.000530891\tvalid_1's RMSPE: 0.245878\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[537]\ttraining's rmse: 0.000461056\ttraining's RMSPE: 0.213524\tvalid_1's rmse: 0.000525453\tvalid_1's RMSPE: 0.242704\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55073023e6004fb2ac7c70becb020aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001796\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's rmse: 0.000465971\ttraining's RMSPE: 0.215908\tvalid_1's rmse: 0.000532043\tvalid_1's RMSPE: 0.245374\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001804\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's rmse: 0.000480576\ttraining's RMSPE: 0.222063\tvalid_1's rmse: 0.000542554\tvalid_1's RMSPE: 0.252295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's rmse: 0.000465856\ttraining's RMSPE: 0.215553\tvalid_1's rmse: 0.000529771\tvalid_1's RMSPE: 0.245359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's rmse: 0.000467177\ttraining's RMSPE: 0.216358\tvalid_1's rmse: 0.000526596\tvalid_1's RMSPE: 0.243232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59abf819395149b784fc107a786153d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001796\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000604577\ttraining's RMSPE: 0.280132\tvalid_1's rmse: 0.00064821\tvalid_1's RMSPE: 0.298949\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001804\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000603916\ttraining's RMSPE: 0.279056\tvalid_1's rmse: 0.000656018\tvalid_1's RMSPE: 0.305057\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5977\n",
      "[LightGBM] [Info] Number of data points in the train set: 321699, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 75 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[202], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m x_data \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     12\u001b[0m y_data \u001b[38;5;241m=\u001b[39m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 15\u001b[0m gs_res \u001b[38;5;241m=\u001b[39m grid_search(\n\u001b[0;32m     16\u001b[0m     lgbm_trainer, x_data, y_data, search_grid, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, randomise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m gs_res\u001b[38;5;241m.\u001b[39msearch_results\n",
      "Cell \u001b[1;32mIn[201], line 112\u001b[0m, in \u001b[0;36mgrid_search\u001b[1;34m(_model_trainer, X, y, search_grid, n_iter, cv, randomise, n_jobs)\u001b[0m\n\u001b[0;32m    109\u001b[0m kf \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39mcv, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Run the grid search\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m results: List[GridSearchResult] \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mn_jobs)(delayed(cv_train)(_model_trainer, kf, X, y, params) \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m tqdm(param_combinations))\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Collect the results\u001b[39;00m\n\u001b[0;32m    115\u001b[0m search_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([r\u001b[38;5;241m.\u001b[39msearch_results \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Ayden\\miniconda3\\envs\\ml\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Ayden\\miniconda3\\envs\\ml\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "Cell \u001b[1;32mIn[201], line 75\u001b[0m, in \u001b[0;36mcv_train\u001b[1;34m(_model_trainer, kf, X, y, params)\u001b[0m\n\u001b[0;32m     72\u001b[0m     X_train, y_train \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mloc[train_idx], y[train_idx]\n\u001b[0;32m     73\u001b[0m     X_valid, y_valid \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mloc[valid_idx], y[valid_idx]\n\u001b[1;32m---> 75\u001b[0m     model_res \u001b[38;5;241m=\u001b[39m _model_trainer(X_train, y_train, X_valid, y_valid, params)\n\u001b[0;32m     76\u001b[0m     cv_models\u001b[38;5;241m.\u001b[39mappend(model_res)\n\u001b[0;32m     78\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[1;32mIn[201], line 46\u001b[0m, in \u001b[0;36mlgbm_trainer\u001b[1;34m(X_train, y_train, X_valid, y_valid, params)\u001b[0m\n\u001b[0;32m     43\u001b[0m X_train_lgb \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_train, y_train, categorical_feature\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstock_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msquare(y_train))\n\u001b[0;32m     44\u001b[0m X_valid_lgb \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_valid, y_valid, categorical_feature\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstock_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msquare(y_valid))\n\u001b[1;32m---> 46\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m     47\u001b[0m     params, \n\u001b[0;32m     48\u001b[0m     X_train_lgb, \n\u001b[0;32m     49\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39m[X_train_lgb, X_valid_lgb], \n\u001b[0;32m     50\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, \n\u001b[0;32m     51\u001b[0m     feval\u001b[38;5;241m=\u001b[39mfeval_rmspe\n\u001b[0;32m     52\u001b[0m )\n\u001b[0;32m     53\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m     54\u001b[0m y_valid_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_valid)\n",
      "File \u001b[1;32mc:\\Users\\Ayden\\miniconda3\\envs\\ml\\Lib\\site-packages\\lightgbm\\engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    296\u001b[0m     cb(\n\u001b[0;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m         )\n\u001b[0;32m    305\u001b[0m     )\n\u001b[1;32m--> 307\u001b[0m booster\u001b[38;5;241m.\u001b[39mupdate(fobj\u001b[38;5;241m=\u001b[39mfobj)\n\u001b[0;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ayden\\miniconda3\\envs\\ml\\Lib\\site-packages\\lightgbm\\basic.py:4136\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   4134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4135\u001b[0m _safe_call(\n\u001b[1;32m-> 4136\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterUpdateOneIter(\n\u001b[0;32m   4137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[0;32m   4138\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mbyref(is_finished),\n\u001b[0;32m   4139\u001b[0m     )\n\u001b[0;32m   4140\u001b[0m )\n\u001b[0;32m   4141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_grid = {\n",
    "    \"objective\": [\"rmse\"], \n",
    "    \"metric\": [\"rmse\"], \n",
    "    'early_stopping_rounds': [75],\n",
    "    \"num_leaves\": [500, 1000, 5000],\n",
    "    \"max_depth\": [50, 100],\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1],\n",
    "    \"reg_alpha\": [0, 0.01],\n",
    "}\n",
    "\n",
    "x_data = df_train.drop(columns=['row_id', 'target', 'time_id'])\n",
    "y_data = df_train['target']\n",
    "\n",
    "\n",
    "gs_res = grid_search(\n",
    "    lgbm_trainer, x_data, y_data, search_grid, n_iter=32, cv=4, randomise=True\n",
    ")\n",
    "gs_res.search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
